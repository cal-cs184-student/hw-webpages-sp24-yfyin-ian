<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184/284A Rasterizer</title>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184/284A: Computer Graphics and Imaging, Spring 2024</h1>
<h1 align="middle">Homework 1: Rasterizer</h1>
<h2 align="middle">Jared Basilio & Yifan Yin</h2>

<br><br>
<a href="https://cal-cs184-student.github.io/hw-webpages-sp24-JaredBasilio/hw1/index.html">Actual Website</a>

<div>


<h2 align="middle">Overview</h2>
<!-- <p>Give a high-level overview of what you implemented in this homework Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.</p> -->
<p>
  During this assignment we implemented basic rendering of 2D vector images, progressively building on top
  of previous tasks throughout the assignment. The assignment was seperated in two major parts: Rasterization and Sampling.
  We first implented filling polygons based on the vertices of the triangles and then provided antialiasing to 
  the edges of these samples for smoother edges. We then implemented transformation (translate, scale, and roate) 
  of polygons within a 2D space. To texture these polygons with basic colors, we implemented Barycentric coordinates
  to interpolate values across the area of a triangle. Moreover, we implemented triangle coloring that is dependent on
  a given text and texture coordinates. Finally, we implemented sampling on different mipmap levels.
</p>


<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

<h3>How to rasterize triangles</h4>
<p>
  A naive approach to rasterize triangles is to iterate through a range of x and
  y coordinates to determine if a pixel is within a triangle. If so, we fill the pixel
  with the provided color. We bounded our range for filling to the 
  minimum and maximum values of our axis'. If we were given
  coordinates that were out of the bounds of the screen, we bounded
  them to 0 or the maximum size of the width or height. Determining if a pixel
  is in our triangle utilizes the line test.
</p>

<h3>Line Test</h3>
<p>
  This test utilizes the vertices of a triangle to determine if a point 
  is within the triangle. Essentially, the triangle is thought of as three half planes
  where the intersection creates a triangle. To determine if a point is apart of all
  of the half planes, we utilize the implicit line equaion.
  <h4>Implicit Line Equation</h4>
  A visual representation of our vectors are drawn below. Our main line of
  focus is the line creating by \(P_1 \) and \(P_2 \). The line created by these two points
  seperates our plane into two sections. A general perpendicular vector(the normal vector) 
  is defined as \((-y,x)\). Similarly the opposite perpendicular vector is defined as
  \((y, -x)\). Therefore any point that follow the equation
  \[N = Perp(T) = (-(y_3 - y_1), x_3 - x_1) \]
  are on the normal vector. Now consider an arbitary point \((x_2, y_2)\) and the line
  created by \(P_1 \) creates a new line \(V = (x_3 - x_1, y_3 - y_1) \). If
  we got the dot product of the normal vector \(N \) and the new line \(V \),
  we can easily classify if the the point is more in the general direction
  of the \(N \) vector, or more in the direction of the opposite vector. This
  idea defines the \(L(x,y) \) equation. By rearranging the values utilized in this equation,
  we diverge to our general setup of the implicit line equation.
  \[dX_i = X_{i + 1} - X_i\]
  \[dY_i = Y_{i + 1} - Y_i\]
  \[L_i(x,y) = -(x - X_i)dY_i + (Y - Y_i)dX_i \]
  \[=A_ix + B_iy + C_i \]
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img 
            src="images/task1/vectors.png" 
            align="middle" 
            width="400px"
          />
          <figcaption align="middle">Vector Drawing</figcaption>
        </td>
      </tr>
    </table>
  </div>
</p>

<p>
  For a given point \((x,y) \), the point is classified relative to the line as follow:
  \[L(x,y) > 0 \textit{ above the line}\]
  \[L(x,y) = 0 \textit{ on the line}\]
  \[L(x,y) < 0 \textit{ below the line}\]
  Back to our rasterizaton process, we do this check on all edges that segment our plane.
  If the Implicit Line Equation test is greater than 0 for all edges, then we can
  conclude that the point is definitely inside the triangle. But what if the point lies on an edge?
</p>


<h3>Line Test Edge Cases</h3>
<p>
  For our implementation, we filled all edges. In other words, when \(L(x,y) \geq 0\) we fill the pixel.
</p>

<h3>Efficiency</h3>
<p>
  Initially we utilized a range similar to <code>rasterize_point</code> to fill out the triangle. 
  Since we can fit any shape in a square bounded by the range of the x coordinates and 
  the range of y coordinates, we can limit our focal point to checking pixels 
  within this range to avoid pixels that cannot be in our triangle. Our
  <code>fill_pixel</code> logic that utilizes only mathematical operations therefore
  this should only run at \(O(1) \) time complexity. Therefore our rasterization process
  runs at most \(O(MN)\) time complexity where \(M \) is the range of the x axis and
  \(N \) is the range of the y axis.
</p>

<h3>Screenshots</h3>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task1/basic:test4-complete.png" align="middle" width="400px"/>
        <figcaption align="middle">screenshot of basic/test4.svg</figcaption>
      </td>
      <td>
        <img src="images/task1/interesting.png" align="middle" width="400px"/>
        <figcaption align="middle">Interesting Part with Pixel Inspector</figcaption>
      </td>
    </tr>
  </table>
</div>

<h3>Optimization</h3>
<p>
  To improve efficiency for our for loops, we utilized 
  <code>
    pragma omp parallel for
  </code> 
  to parallelize our for loops and iterated through the 
  y-pixels first instead of the x-pixels to reduce cache misses.
</p>

<h3 align="middle">Part 2: Antialiasing by Supersampling</h3>
<h4>How we implemented supersampling</h4>
<p>
  For supersampling, we modified the renderer to include a square root sample rate and half sample dist value
  as a class value. Additionally, we now have another fill_pixel function that fills the pixel determined by these two new values.
  Finally, we added super sample support to the <code>resolve_to_framebuffer</code> function to
  translate the internal buffer of the rasterizer to the screenbuffer. In this function, we get
  a range for our buffer and calculates the color for each of our pixels. It then scales the result
  by dividing by the sample_rate.
</p>

<h4>Why is it important?</h4>
<p>
  Supersampling creates a better visual representation of our triangle by being less strict on which pixel should be considered
  in our final rasterization process. This gives the illusion that the edges of our triangle are smoother than what they
  were using the classification algorithm.
</p>

<h4>What modifications did we make in the process?</h4>
<p>
  Rather than evaluating each pixel as in or out, we evaluated each pixel multiple times by using the square root sampling rate. The new coordinate becomes
  \[xp = sx + (1 + 2 \times i) \times (0.5 / square root sample rate) \]
  \[yp = sy + (1 + 2 \times j) \times (0.5 / square root sample rate) \]
  where \((xp, yp) \) are the new coordinates we are evaluating, \((sx, sy) \) are the original coordinates, \((i,j) \) are coordinates within
  our square root sample rate box, and square root sample rate is the given sample rate.
</p>

<h4>How did we antialias our triangles?</h4>
<p>
  We antialiased our triangles by filling in additional points that follow our square root sample rate.
</p>

<h3 align="middle">Comparisons</h3>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task2/1_pixel_default.png" align="middle" width="400px"/>
        <figcaption align="middle">1 Pixel Default Viewing Params</figcaption>
      </td>
      <td>
        <img src="images/task2/4_pixel_default.png" align="middle" width="400px"/>
        <figcaption align="middle">4 Pixel Default Viewing Params</figcaption>
      </td>
      <td>
        <img src="images/task2/16_pixel_default.png" align="middle" width="400px"/>
        <figcaption align="middle">16 Pixel Default Viewing Params</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>As you can see above, the difference in the photos are very miniscule.</p>

<div align="middle">
  <table style="width=80%">
    <tr>
      <td>
        <img src="images/task2/1_pixel_zoom.png" align="middle" width="400px"/>
        <figcaption align="middle">1 Pixel Zoom View</figcaption>
      </td>
      <td>
        <img src="images/task2/4_pixel_zoom.png" align="middle" width="400px"/>
        <figcaption align="middle">4 Pixel Zoom View</figcaption>
      </td>
      <td>
        <img src="images/task2/16_pixel_zoom.png" align="middle" width="400px"/>
        <figcaption align="middle">16 Pixel Zoom View</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>
  Zooming in we can see the antialiasing in action. With 1 pixel sampling, there are jaggies that are unconnected from the 
  main part of the triangle. As we increase the sample rate, the seperation between the outliing pixel
  and the rest of the triangle becomes more connected with darker pixels as the sampling rate increases. Additionally, the jump
  from the triangle to the background becomes a lot smoother, having a gradient transition from the color
  of the triangle to the background.
</p>

<h3 align="middle">Part 3: Transforms</h3>
<p>For our robot, we tried recreating the silhouette similar to the person crossing used for crosswalks.</p>
<div align="middle">
  <table style="width=80%">
    <tr>
      <td>
        <img src="images/task3/running_man.png" align="middle" width="400px"/>
        <figcaption align="middle">my_robot.svg</figcaption>
      </td>
      <td>
        <img src="images/task3/crosswalk.png" align="middle" width="400px"/>
        <figcaption align="middle">Inspiration</figcaption>
      </td>
    </tr>
  </table>
</div>

<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>
<h3>What are Barycentric coordinates?</h3>
<p>
  Barycentric coordinates represent the position of a point relative to 3 other points/vertices. 
  Consider three vertices \(A\), \(B\), and \(C\). Any point \(P\) within the triangle can be represented by non-negative
  numbers \(alpha (\alpha) \), \(beta (\beta) \), and \(gamma (\gamma) \) such that 
  \(\alpha + \beta + \gamma = 1 \). These letters are meant to represent the weight of each vertice
  \(A\), \(B\), and \(C\) to reach point P. 
</p>
<p>
  For example, if our vector of weights \((\alpha \), \(\beta \), \(\gamma \)) = (1,0,0), our point
  will be on vertex A since that has the only weight. As seen in the triangle below, the top left corner is the most red but
  as we get farther from the corner we transition to black.
</p>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task4/cornerRed.png" align="middle" width="400px"/>
        <figcaption align="middle">Corner A (Red) leaning</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
  If our vector of weights \((\alpha \), \(\beta \), \(\gamma \)) = (1/3,1/3,1/3), our point
  will be set in the center of the \(ACB \) triangle. As seen in the triangle below, the middle of the triangle is where
  all the colors are the most homogenous and moving away from the middle starts to flow into each designated color.
</p>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task4/middle.png" align="middle" width="400px"/>
        <figcaption align="middle">Triangle Gradient</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
  In computer graphics, these points can be positions, texture coordinates, color, normal vectors, material attributes etc. These create
  better textures as we can have smoother transitions into other triangles, creating an illusion of whole shapes rather than a
  combination of individual triangles.
</p>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task4/gradient.png" align="middle" width="400px"/>
        <figcaption align="middle">svg/basic/test7.svg</figcaption>
      </td>
    </tr>
  </table>
</div>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
<h4>What is pixel sampling?</h4>
<p>
  Pixel Sampling is the act of utilizing a subset of pixels
  to represent the image/vector at a lower resolution. This is done to reduce the size
  of the file of an image while also maintaining the general quality of the image.
</p>
<h4>How did we implement pixel sampling?</h4>
<p>
  To implement pixel sampling, we needed to modify three functions
  <code>Texture::sample_nearest</code>, and
  <code>Texture::sample_bilinear</code>.
</p>
<br />
<code>Texture::sample_nearest</code>
<br />
<p>
  For this function, we mapped the provided \((u,v)\) coordinates from
  a \([0,1] \times [0,1]\) space to a  \( [0, mip.width ) \times [0, mip.height ) \) space.
  After we bounded these newly rounded values to the size of the mip. We returned
  the texel of the coordinate of the new mapping.
</p>
<code>Texture::sample_bilinear</code>
<p>
  For this function, we mapped the values of the input vector to the mip width
  and height then flooring the values to get our sampling integers \((tu, tv) \). To ensure we are
  not comparing pixel out of bounds, we check that \(tu + 1 \) and \(tv + 1 \) are not
  reaching out of the width and height of the mip. If we don't we can add another displaced coordinate
  for our values. For all 4 combinations of the coordinates in our space, we get the texel at
  that coordinate. To interpolate our neighboring texels, we get the weight
  for linear interpolation by getting the difference between our mapped floating
  point value and the rounded integer value. Our weights are:
  \[s = u - tu \]
  \[t = v - tv \]
  We evaluate the linear interpolation using \(s \) for the columns of our \(2 \times 2 \) square first using the equation
  \[(1 - x)a + xb \] where x is the weight and \(a \) and \(b \) are the coordinates respectively. The values we evaluated from
  this columns are linearly interpolated with the \(t \) weight. Our returned value is the resulting texture sample.
</p>
<br />

<h4>Nearest vs. Bilinear</h4>
<p>
  Nearest Neighbor Interpolation and Bilinear Interpolation are methods of resampling to determine how the
  cell values of the output raster. Nearest Neighbor Interpolation inherits the value of the nearest pixel
  in the input image. This method is the quickest but produces very jagged edges.
  Bilinear Interpolation however uses the weighted average of the four nearest call centers. This method
  has much smoother transitions between colors but is also more computationally heavy expensive.
</p>

<h4>Comparisons</h4>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task5/nearest_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Sampling, 1 sample per pixel</figcaption>
      </td>
      <td>
        <img src="images/task5/nearest_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Sampling, 16 sample per pixel</figcaption>
      </td>
    </tr>
    <tr>
      <td>
        <img src="images/task5/bilinear_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear Sampling, 1 sample per pixel</figcaption>
      </td>
      <td>
        <img src="images/task5/bilinear_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear Sampling, 16 sample per pixel</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<p>
  The first aspect that stands out between the pixels is how smooth the edges are. The bilinear interpolation sampling has softer edges than the nearest
  sampling method. However, zooming in and out of the pictures are a lot faster when using the nearest sampling method over the bilinear method. There
  will be more differences in the two edges when there is a higher frequency of the change between colors and the lines are very thin. This is because
  bilinear represents more of an average of the represented colors while nearest represents more of an absolute categorization. Additionally,
  many thin lines means more edges and more edges means more utilization of this sampling.
</p>


<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>
<h4>What is Level Sampling?</h4>
<p>
  Level sampling or mipmapping is a rendering optimization technique that computes multiple versions of a texture at different resolution
  to be used depending on the distance or orientation of the camera faced towards it.
</p>
<h4>How did we implement level sampling?</h4>
<p>
  We implemented level sampling by modifying our 
  <code>RasterizerImp::rasterize_textured_triangle</code>,
  <code>Texture::sample</code>, and 
  <code>Texture::get_level</code> functions.
</p>
<code>RasterizerImp::rasterize_textured_triangle</code>
<p>
  In this function, we find our compute parameters that will be filled in our sampling method.
  For \((x,y) \), \((x + 1,y) \), and \((x,y + 1) \), we find the barycentric coordinates given these points
  and the points of the triangle, then multiply each result by the weights provided.
  The result is passed into our provided sampling method.
</p>
<code>Texture::sample</code>
<p>
  In the sample function, we first calculate the level by the get_level and sp.lsm, and calculate the corresponding color using the psm.
</p>
<code>Texture::get_level</code>
<p>
  In the get level function, we utilized the following function to determine where du/dx and dv/dx is
  the change in distances from the center point.
  \[L = max(\sqrt{(\frac{du}{dx})^2 + (\frac{dv}{dx})^2},\sqrt{(\frac{du}{dy})^2 + (\frac{dv}{dy})^2})\]
  \[D = log_2L \]
</p>
<h4>Tradeoffs</h4>
<p>
  Mipmap requires more storage since multiple versions of each texture are stored
  and accessing multiple different versions of a texture could increase render times.
</p>

<!-- <p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/image1.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="images/image2.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/image3.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="images/image4.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
  </table>
</div>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>


<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>



<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3> -->

</body>
</html>
